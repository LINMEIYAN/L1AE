{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We provide a ipython notebook to walk you through the trainining and evaluation of our l1-AE (as well as other baselines).\n",
    "# The dataset we will use is the synthetic1 dataset (see the description in our paper).\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from __future__ import division\n",
    "from time import time\n",
    "from model import L1AE\n",
    "from datasets import synthetic_block_sparse_data\n",
    "from utils import LBCS, l1_min_avg_err, CoSaMP_block_avg_err\n",
    "from baselines import block_sparse_CoSaMP, l1_min, PCA_l1, simple_AE_l1, std_AE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 43\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random Synthetic1 dataset, which is a 1-block sparse dataset with block size 10.\n",
    "input_dim = 1000\n",
    "block_dim = 10\n",
    "sparsity_level = 1\n",
    "num_samples = 10000\n",
    "X_train, X_valid, X_test = synthetic_block_sparse_data(input_dim, block_dim, \n",
    "                                                      sparsity_level, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 1000), (2000, 1000), (2000, 1000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shapes of X_train, X_valid, X_test should be [6000, 1000], [2000, 1000], [2000, 1000].\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tf.session.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# Define an l1-AE object. Before that, we need to define two parameters: emb_dim and decoder_num_steps.\n",
    "emb_dim = 20  # This is the number of measurements, i.e., the measurment matrix has shape [1000,20].\n",
    "decoder_num_steps = 10  # This the decoder depth parameter \"T\" described in the paper. \n",
    "sparse_AE = L1AE(sess, input_dim, emb_dim, decoder_num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 00000', 'TrainSqErr: 1.313157', 'ValidSqErr: 0.993312', 'StepSize: 0.125272')\n",
      "('Epoch: 00050', 'TrainSqErr: 0.113554', 'ValidSqErr: 0.122498', 'StepSize: 0.320940')\n",
      "('Epoch: 00100', 'TrainSqErr: 0.049317', 'ValidSqErr: 0.061615', 'StepSize: 0.547314')\n",
      "('Epoch: 00150', 'TrainSqErr: 0.030776', 'ValidSqErr: 0.038761', 'StepSize: 0.545453')\n",
      "('Epoch: 00200', 'TrainSqErr: 0.024706', 'ValidSqErr: 0.030269', 'StepSize: 0.525091')\n",
      "('Epoch: 00250', 'TrainSqErr: 0.021811', 'ValidSqErr: 0.025888', 'StepSize: 0.508212')\n",
      "Optimization Finished!\n",
      "Training takes 281 epochs in 69.062271 secs\n",
      "Training loss: 0.020992\n",
      "Validation loss: 0.024904\n"
     ]
    }
   ],
   "source": [
    "# Training parameters.\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "max_training_epochs = 2e4\n",
    "# Early-stopping parameters (X_valid is used for early-stopping).\n",
    "display_interval = 50\n",
    "validation_interval = 10\n",
    "max_steps_not_improve = 1\n",
    "# Start training...it should be done in a couple of minutes.\n",
    "sparse_AE.train(X_train, X_valid, batch_size, learning_rate,\n",
    "                max_training_epochs, display_interval, \n",
    "                validation_interval, max_steps_not_improve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15571894960367044\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained autoencoder.\n",
    "# We start with the autoencoder itself. The test RMSE is around 0.15.\n",
    "l1ae_test_RMSE = np.sqrt(sparse_AE.inference(X_test, batch_size))\n",
    "print l1ae_test_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635\n",
      "0.08434439291903947\n"
     ]
    }
   ],
   "source": [
    "# Now we evalute our method \"l1-AE + l1-min pos\".\n",
    "G = sparse_AE.sess.run(sparse_AE.encoder_weight)  # Get the learned measurement matrix.\n",
    "Y = X_test.dot(G)  # Compute the linear measurments\n",
    "# Solve an l1-minimization decoder. This takes less than 1 minute.\n",
    "l1ae_l1_err_pos, l1ae_l1_exact_pos, _ = l1_min_avg_err(np.transpose(G), Y, X_test, use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be around 97% at emb_dim=20.\n",
    "# By exact recovery, we mean that the reconstruction error is less than 1e-10.\n",
    "print l1ae_l1_exact_pos\n",
    "# Print the test RMSE error of our method. This value will be around 0.05 at emb_dim=20.\n",
    "print l1ae_l1_err_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9860925512463197\n"
     ]
    }
   ],
   "source": [
    "# We now evalute the method \"Gaussian + l1-min pos\".\n",
    "G = np.random.randn(input_dim, emb_dim)/np.sqrt(emb_dim)\n",
    "Y = X_test.dot(G)  \n",
    "g_err_pos, g_exact_pos, _ = l1_min_avg_err(np.transpose(G), Y, X_test, use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be 0 at emb_dim=20.\n",
    "print g_exact_pos\n",
    "# Print the test RMSE error of this method. This value will be around 1 at emb_dim=20.\n",
    "print g_err_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.3056192545835437\n"
     ]
    }
   ],
   "source": [
    "# We now evalute the method \"PCA + l1-min pos\".\n",
    "svd = TruncatedSVD(n_components=emb_dim)\n",
    "svd.fit(X_train)\n",
    "G = svd.components_\n",
    "Y = svd.transform(X_test)\n",
    "p_err_pos, p_exact_pos, _ = l1_min_avg_err(G, Y, X_test, use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be 0 at emb_dim=20.\n",
    "print p_exact_pos\n",
    "# Print the test RMSE error of this method. This value will be around 2 at emb_dim=20.\n",
    "print p_err_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7875\n",
      "0.4609772228646444\n"
     ]
    }
   ],
   "source": [
    "# We now evalute the method \"Gauss + model-based CoSaMP pos\".\n",
    "G = np.random.randn(input_dim, emb_dim)/np.sqrt(emb_dim)\n",
    "Y = X_test.dot(G)\n",
    "cosamp_g_err_pos, cosamp_g_exact_pos, _ = CoSaMP_block_avg_err(np.transpose(G), Y, X_test,\n",
    "                                                               block_dim, sparsity_level,\n",
    "                                                               use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be around 80% at emb_dim=20.\n",
    "print cosamp_g_exact_pos\n",
    "# Print the test RMSE error of this method. This value will be around 0.4 at emb_dim=20.\n",
    "print cosamp_g_err_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9726235499476165\n"
     ]
    }
   ],
   "source": [
    "# We now evalute the method \"LBCS + l1-min pos\".\n",
    "G = np.random.randn(input_dim, input_dim)/np.sqrt(input_dim)\n",
    "A, Y = LBCS(G, emb_dim, X_train, X_test)\n",
    "LBCS_g_l1_pos_err, LBCS_g_l1_pos_exact, _ = l1_min_avg_err(np.transpose(A), Y,\n",
    "                                                           X_test, use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be around 0 at emb_dim=20.\n",
    "print LBCS_g_l1_pos_exact\n",
    "# Print the test RMSE error of this method. This value will be around 1 at emb_dim=20.\n",
    "print LBCS_g_l1_pos_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 00000', 'TrainSqErr: 0.997240', 'ValidSqErr: 0.996557')\n",
      "('Epoch: 00050', 'TrainSqErr: 0.766941', 'ValidSqErr: 0.782064')\n",
      "('Epoch: 00100', 'TrainSqErr: 0.483520', 'ValidSqErr: 0.508334')\n",
      "('Epoch: 00150', 'TrainSqErr: 0.356732', 'ValidSqErr: 0.370294')\n",
      "('Epoch: 00200', 'TrainSqErr: 0.349294', 'ValidSqErr: 0.361474')\n",
      "Optimization Finished!\n",
      "Training takes 201 epochs in 13.766834 secs\n",
      "Training loss: 0.349294\n",
      "Validation loss: 0.361474\n",
      "0.354\n",
      "0.4761375497843256\n"
     ]
    }
   ],
   "source": [
    "# We now evalute the method \"simple AE + l1-min pos\". \n",
    "learning_rate = 0.1  # Training will finish within a minute.\n",
    "err, G = simple_AE_l1(input_dim, emb_dim, X_train, X_valid, X_test,\n",
    "                      batch_size, learning_rate,\n",
    "                      max_training_epochs, display_interval,\n",
    "                      validation_interval, max_steps_not_improve)\n",
    "Y = X_test.dot(G)\n",
    "sim_l1_err_pos, sim_l1_exact_pos, _ = l1_min_avg_err(np.transpose(G), Y,\n",
    "                                                     X_test, use_pos=True)\n",
    "# Print the faction of exactly recovered test data points. This value will be around 40% at emb_dim=20.\n",
    "print sim_l1_exact_pos\n",
    "# Print the test RMSE error of this method. This value will be around 0.5 at emb_dim=20.\n",
    "print sim_l1_err_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 00000', 'TrainSqErr: 0.995236', 'ValidSqErr: 0.994779')\n",
      "('Epoch: 00050', 'TrainSqErr: 0.865111', 'ValidSqErr: 0.867789')\n",
      "('Epoch: 00100', 'TrainSqErr: 0.461987', 'ValidSqErr: 0.469618')\n",
      "('Epoch: 00150', 'TrainSqErr: 0.445619', 'ValidSqErr: 0.456652')\n",
      "('Epoch: 00200', 'TrainSqErr: 0.416674', 'ValidSqErr: 0.434419')\n",
      "('Epoch: 00250', 'TrainSqErr: 0.376530', 'ValidSqErr: 0.400282')\n",
      "('Epoch: 00300', 'TrainSqErr: 0.346185', 'ValidSqErr: 0.370498')\n",
      "('Epoch: 00350', 'TrainSqErr: 0.327988', 'ValidSqErr: 0.351261')\n",
      "('Epoch: 00400', 'TrainSqErr: 0.318595', 'ValidSqErr: 0.336912')\n",
      "('Epoch: 00450', 'TrainSqErr: 0.313865', 'ValidSqErr: 0.329677')\n",
      "('Epoch: 00500', 'TrainSqErr: 0.307759', 'ValidSqErr: 0.324119')\n",
      "('Epoch: 00550', 'TrainSqErr: 0.306392', 'ValidSqErr: 0.320474')\n",
      "Optimization Finished!\n",
      "Training takes 561 epochs in 41.585304 secs\n",
      "Training loss: 0.306328\n",
      "Validation loss: 0.320480\n",
      "0.5673495240768203\n"
     ]
    }
   ],
   "source": [
    "# We now train a standard 4-layer ReLU autoencoder.\n",
    "layer1_dim = 100    # Tuned based on the performance over the validation set.\n",
    "layer2_dim = emb_dim\n",
    "test_sq_loss = std_AE(input_dim, layer1_dim, layer2_dim, X_train,\n",
    "                      X_valid, X_test, batch_size, learning_rate,\n",
    "                      max_training_epochs, display_interval,\n",
    "                      validation_interval, max_steps_not_improve)\n",
    "std_ae_test_err = np.sqrt(test_sq_loss)  # test RMSE of 4-layer AE \n",
    "print std_ae_test_err  # The value is around 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
